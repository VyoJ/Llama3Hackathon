Title: Retrieval-Augmented Image Captioning - LlamaIndex

URL Source: https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/

Markdown Content:
Retrieval-Augmented Image Captioning - LlamaIndex


In this example, we show how to leverage [LLaVa + Replicate](https://replicate.com/yorickvp/llava-13b) for image understanding/captioning and retrieve relevant unstructured text and embedded tables from Tesla 10K file according to the image understanding.

1.  LlaVa can provide image understanding based on user prompt.
2.  We use Unstructured to parse out the tables, and use LlamaIndex recursive retrieval to index/retrieve tables and texts.
3.  We can leverage the image understanding from Step 1 to retrieve relevant information from knowledge base generated by Step 2 (which is indexed by LlamaIndex)

Context for LLaVA: Large Language and Vision Assistant

*   [Website](https://llava-vl.github.io/)
*   [Paper](https://arxiv.org/abs/2304.08485)
*   [Github](https://github.com/haotian-liu/LLaVA)
*   LLaVA is now supported in llama.cpp with 4-bit / 5-bit quantization support: [See here.](https://github.com/ggerganov/llama.cpp/pull/3436) \[Deprecated\]
*   LLaVA 13b is now supported in Replicate: [See here.](https://replicate.com/yorickvp/llava-13b)

For LlamaIndex: LlaVa+Replicate enables us to run image understanding locally and combine the multi-modal knowledge with our RAG knowledge base system.

TODO: Waiting for [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) supporting LlaVa model in python wrapper. So LlamaIndex can leverage `LlamaCPP` class for serving LlaVa model directly/locally.

Using Replicate serving LLaVa model through LlamaIndex[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#using-replicate-serving-llava-model-through-llamaindex)
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Build and Run LLaVa models locally through Llama.cpp (Deprecated)[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#build-and-run-llava-models-locally-through-llamacpp-deprecated)

1.  git clone [https://github.com/ggerganov/llama.cpp.git](https://github.com/ggerganov/llama.cpp.git)
2.  `cd llama.cpp`. Checkout llama.cpp repo for more details.
3.  `make`
4.  Download Llava models including `ggml-model-*` and `mmproj-model-*` from [this Hugging Face repo](https://huggingface.co/mys/ggml_llava-v1.5-7b/tree/main). Please select one model based on your own local configuration
5.  `./llava` for checking whether llava is running locally

In \[ \]:

Copied!

%pip install llama\-index\-readers\-file
%pip install llama\-index\-multi\-modal\-llms\-replicate

%pip install llama-index-readers-file %pip install llama-index-multi-modal-llms-replicate

In \[ \]:

Copied!

%load\_ext autoreload
% autoreload 2

%load\_ext autoreload % autoreload 2

UsageError: Line magic function \`%\` not found.

In \[ \]:

Copied!

!pip install unstructured

!pip install unstructured

In \[ \]:

Copied!

from unstructured.partition.html import partition\_html
import pandas as pd

pd.set\_option("display.max\_rows", None)
pd.set\_option("display.max\_columns", None)
pd.set\_option("display.width", None)
pd.set\_option("display.max\_colwidth", None)

from unstructured.partition.html import partition\_html import pandas as pd pd.set\_option("display.max\_rows", None) pd.set\_option("display.max\_columns", None) pd.set\_option("display.width", None) pd.set\_option("display.max\_colwidth", None)

WARNING: CPU random generator seem to be failing, disabling hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff

Perform Data Extraction from Tesla 10K file[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#perform-data-extraction-from-tesla-10k-file)
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

In these sections we use Unstructured to parse out the table and non-table elements.

### Extract Elements[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#extract-elements)

We use Unstructured to extract table and non-table elements from the 10-K filing.

In \[ \]:

Copied!

!wget "https://www.dropbox.com/scl/fi/mlaymdy1ni1ovyeykhhuk/tesla\_2021\_10k.htm?rlkey=qf9k4zn0ejrbm716j0gg7r802&dl=1" \-O tesla\_2021\_10k.htm
!wget "https://docs.google.com/uc?export=download&id=1THe1qqM61lretr9N3BmINc\_NWDvuthYf" \-O shanghai.jpg
!wget "https://docs.google.com/uc?export=download&id=1PDVCf\_CzLWXNnNoRV8CFgoJxv6U0sHAO" \-O tesla\_supercharger.jpg

!wget "https://www.dropbox.com/scl/fi/mlaymdy1ni1ovyeykhhuk/tesla\_2021\_10k.htm?rlkey=qf9k4zn0ejrbm716j0gg7r802&dl=1" -O tesla\_2021\_10k.htm !wget "https://docs.google.com/uc?export=download&id=1THe1qqM61lretr9N3BmINc\_NWDvuthYf" -O shanghai.jpg !wget "https://docs.google.com/uc?export=download&id=1PDVCf\_CzLWXNnNoRV8CFgoJxv6U0sHAO" -O tesla\_supercharger.jpg

In \[ \]:

Copied!

from llama\_index.readers.file import FlatReader
from pathlib import Path

reader \= FlatReader()
docs\_2021 \= reader.load\_data(Path("tesla\_2021\_10k.htm"))

from llama\_index.readers.file import FlatReader from pathlib import Path reader = FlatReader() docs\_2021 = reader.load\_data(Path("tesla\_2021\_10k.htm"))

In \[ \]:

Copied!

from llama\_index.core.node\_parser import UnstructuredElementNodeParser

node\_parser \= UnstructuredElementNodeParser()

from llama\_index.core.node\_parser import UnstructuredElementNodeParser node\_parser = UnstructuredElementNodeParser()

In \[ \]:

Copied!

import os

REPLICATE\_API\_TOKEN \= "..."  \# Your Relicate API token here
os.environ\["REPLICATE\_API\_TOKEN"\] \= REPLICATE\_API\_TOKEN

import os REPLICATE\_API\_TOKEN = "..." # Your Relicate API token here os.environ\["REPLICATE\_API\_TOKEN"\] = REPLICATE\_API\_TOKEN

In \[ \]:

Copied!

import openai

OPENAI\_API\_KEY \= "sk-..."
openai.api\_key \= OPENAI\_API\_KEY  \# add your openai api key here
os.environ\["OPENAI\_API\_KEY"\] \= OPENAI\_API\_KEY

import openai OPENAI\_API\_KEY = "sk-..." openai.api\_key = OPENAI\_API\_KEY # add your openai api key here os.environ\["OPENAI\_API\_KEY"\] = OPENAI\_API\_KEY

In \[ \]:

Copied!

import os
import pickle

if not os.path.exists("2021\_nodes.pkl"):
    raw\_nodes\_2021 \= node\_parser.get\_nodes\_from\_documents(docs\_2021)
    pickle.dump(raw\_nodes\_2021, open("2021\_nodes.pkl", "wb"))
else:
    raw\_nodes\_2021 \= pickle.load(open("2021\_nodes.pkl", "rb"))

import os import pickle if not os.path.exists("2021\_nodes.pkl"): raw\_nodes\_2021 = node\_parser.get\_nodes\_from\_documents(docs\_2021) pickle.dump(raw\_nodes\_2021, open("2021\_nodes.pkl", "wb")) else: raw\_nodes\_2021 = pickle.load(open("2021\_nodes.pkl", "rb"))

In \[ \]:

Copied!

nodes\_2021, objects\_2021 \= node\_parser.get\_nodes\_and\_objects(raw\_nodes\_2021)

nodes\_2021, objects\_2021 = node\_parser.get\_nodes\_and\_objects(raw\_nodes\_2021)

Setup Composable Retriever[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#setup-composable-retriever)
------------------------------------------------------------------------------------------------------------------------------------------------

Now that we've extracted tables and their summaries, we can setup a composable retriever in LlamaIndex to query these tables.

### Construct Retrievers[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#construct-retrievers)

In \[ \]:

Copied!

from llama\_index.core import VectorStoreIndex

\# construct top-level vector index + query engine
vector\_index \= VectorStoreIndex(nodes\=nodes\_2021, objects\=objects\_2021)
query\_engine \= vector\_index.as\_query\_engine(similarity\_top\_k\=2, verbose\=True)

from llama\_index.core import VectorStoreIndex # construct top-level vector index + query engine vector\_index = VectorStoreIndex(nodes=nodes\_2021, objects=objects\_2021) query\_engine = vector\_index.as\_query\_engine(similarity\_top\_k=2, verbose=True)

In \[ \]:

Copied!

from PIL import Image
import matplotlib.pyplot as plt

imageUrl \= "./tesla\_supercharger.jpg"
image \= Image.open(imageUrl).convert("RGB")

plt.figure(figsize\=(16, 5))
plt.imshow(image)

from PIL import Image import matplotlib.pyplot as plt imageUrl = "./tesla\_supercharger.jpg" image = Image.open(imageUrl).convert("RGB") plt.figure(figsize=(16, 5)) plt.imshow(image)

Out\[ \]:

<matplotlib.image.AxesImage at 0x7f24f9bb8410>

![Image 4: No description has been provided for this image](blob:https://docs.llamaindex.ai/75528dab61e58c68771dc65dbae95f6f)

### Running LLaVa model using Replicate through LlamaIndex for image understanding[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#running-llava-model-using-replicate-through-llamaindex-for-image-understanding)

In \[ \]:

Copied!

from llama\_index.multi\_modal\_llms.replicate import ReplicateMultiModal
from llama\_index.core.schema import ImageDocument
from llama\_index.multi\_modal\_llms.replicate.base import (
    REPLICATE\_MULTI\_MODAL\_LLM\_MODELS,
)

multi\_modal\_llm \= ReplicateMultiModal(
    model\=REPLICATE\_MULTI\_MODAL\_LLM\_MODELS\["llava-13b"\],
    max\_new\_tokens\=200,
    temperature\=0.1,
)

prompt \= "what is the main object for tesla in the image?"

llava\_response \= multi\_modal\_llm.complete(
    prompt\=prompt,
    image\_documents\=\[ImageDocument(image\_path\=imageUrl)\],
)

from llama\_index.multi\_modal\_llms.replicate import ReplicateMultiModal from llama\_index.core.schema import ImageDocument from llama\_index.multi\_modal\_llms.replicate.base import ( REPLICATE\_MULTI\_MODAL\_LLM\_MODELS, ) multi\_modal\_llm = ReplicateMultiModal( model=REPLICATE\_MULTI\_MODAL\_LLM\_MODELS\["llava-13b"\], max\_new\_tokens=200, temperature=0.1, ) prompt = "what is the main object for tesla in the image?" llava\_response = multi\_modal\_llm.complete( prompt=prompt, image\_documents=\[ImageDocument(image\_path=imageUrl)\], )

### Retrieve relevant information from LlamaIndex knowledge base according to LLaVa image understanding[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#retrieve-relevant-information-from-llamaindex-knowledge-base-according-to-llava-image-understanding)

In \[ \]:

Copied!

prompt\_template \= "please provide relevant information about: "
rag\_response \= query\_engine.query(prompt\_template + llava\_response.text)

prompt\_template = "please provide relevant information about: " rag\_response = query\_engine.query(prompt\_template + llava\_response.text)

Retrieval entering id\_1836\_table: TextNode
Retrieving from object TextNode with query please provide relevant information about: The main object for Tesla in the image is a red and white electric car charging station.
Retrieval entering id\_431\_table: TextNode
Retrieving from object TextNode with query please provide relevant information about: The main object for Tesla in the image is a red and white electric car charging station.

### Showing final RAG image caption results from LlamaIndex[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#showing-final-rag-image-caption-results-from-llamaindex)

In \[ \]:

Copied!

print(str(rag\_response))

print(str(rag\_response))

The main object for Tesla in the image is a red and white electric car charging station.

In \[ \]:

Copied!

from PIL import Image
import matplotlib.pyplot as plt

imageUrl \= "./shanghai.jpg"
image \= Image.open(imageUrl).convert("RGB")

plt.figure(figsize\=(16, 5))
plt.imshow(image)

from PIL import Image import matplotlib.pyplot as plt imageUrl = "./shanghai.jpg" image = Image.open(imageUrl).convert("RGB") plt.figure(figsize=(16, 5)) plt.imshow(image)

Out\[ \]:

<matplotlib.image.AxesImage at 0x7f24f787aa50>

![Image 5: No description has been provided for this image](blob:https://docs.llamaindex.ai/ceb5a55a0ecd16e74630802921d9cbf4)

### Retrieve relevant information from LlamaIndex for a new image[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#retrieve-relevant-information-from-llamaindex-for-a-new-image)

In \[ \]:

Copied!

prompt \= "which Tesla factory is shown in the image?"

llava\_response \= multi\_modal\_llm.complete(
    prompt\=prompt,
    image\_documents\=\[ImageDocument(image\_path\=imageUrl)\],
)

prompt = "which Tesla factory is shown in the image?" llava\_response = multi\_modal\_llm.complete( prompt=prompt, image\_documents=\[ImageDocument(image\_path=imageUrl)\], )

In \[ \]:

Copied!

prompt\_template \= "please provide relevant information about: "
rag\_response \= query\_engine.query(prompt\_template + llava\_response.text)

prompt\_template = "please provide relevant information about: " rag\_response = query\_engine.query(prompt\_template + llava\_response.text)

Retrieving with query id None: please provide relevant information about: a large Tesla factory with a white roof, located in Shanghai, China. The factory is surrounded by a parking lot filled with numerous cars, including both small and large vehicles. The cars are parked in various positions, some closer to the factory and others further away. The scene gives an impression of a busy and well-organized facility, likely producing electric vehicles for the global market
Retrieved node with id, entering: id\_431\_table
Retrieving with query id id\_431\_table: please provide relevant information about: a large Tesla factory with a white roof, located in Shanghai, China. The factory is surrounded by a parking lot filled with numerous cars, including both small and large vehicles. The cars are parked in various positions, some closer to the factory and others further away. The scene gives an impression of a busy and well-organized facility, likely producing electric vehicles for the global market
Retrieving text node: We continue to increase the degree of localized procurement and manufacturing there. Gigafactory Shanghai is representative of our plan to iteratively improve our manufacturing operations as we establish new factories, as we implemented the learnings from our Model 3 and Model Y ramp at the Fremont Factory to commence and ramp our production at Gigafactory Shanghai quickly and cost-effectively.

Other Manufacturing

Generally, we continue to expand production capacity at our existing facilities. We also intend to further increase cost-competitiveness in our significant markets by strategically adding local manufacturing, including at Gigafactory Berlin in Germany and Gigafactory Texas in Austin, Texas, which will begin production in 2022.

Supply Chain

Our products use thousands of purchased parts that are sourced from hundreds of suppliers across the world. We have developed close relationships with vendors of key parts such as battery cells, electronics and complex vehicle assemblies. Certain components purchased from these suppliers are shared or are similar across many product lines, allowing us to take advantage of pricing efficiencies from economies of scale.

As is the case for most automotive companies, most of our procured components and systems are sourced from single suppliers. Where multiple sources are available for certain key components, we work to qualify multiple suppliers for them where it is sensible to do so in order to minimize production risks owing to disruptions in their supply. We also mitigate risk by maintaining safety stock for key parts and assemblies and die banks for components with lengthy procurement lead times.

Our products use various raw materials including aluminum, steel, cobalt, lithium, nickel and copper. Pricing for these materials is governed by market conditions and may fluctuate due to various factors outside of our control, such as supply and demand and market speculation. We strive to execute long-term supply contracts for such materials at competitive pricing when feasible, and we currently believe that we have adequate access to raw materials supplies in order to meet the needs of our operations.

Governmental Programs, Incentives and Regulations

Globally, both the operation of our business by us and the ownership of our products by our customers are impacted by various government programs, incentives and other arrangements. Our business and products are also subject to numerous governmental regulations that vary among jurisdictions.

Programs and Incentives

California Alternative Energy and Advanced Transportation Financing Authority Tax Incentives

We have agreements with the California Alternative Energy and Advanced Transportation Financing Authority that provide multi-year sales tax exclusions on purchases of manufacturing equipment that will be used for specific purposes, including the expansion and ongoing development of electric vehicles and powertrain production in California, thus reducing our cost basis in the related assets in our consolidated financial statements included elsewhere in this Annual Report on Form 10-K.

Gigafactory Nevada—Nevada Tax Incentives

In connection with the construction of Gigafactory Nevada, we entered into agreements with the State of Nevada and Storey County in Nevada that provide abatements for specified taxes, discounts to the base tariff energy rates and transferable tax credits in consideration of capital investment and hiring targets that were met at Gigafactory Nevada. These incentives are available until June 2024 or June 2034, depending on the incentive and primarily offset related costs in our consolidated financial statements included elsewhere in this Annual Report on Form 10-K.

Gigafactory New York—New York State Investment and Lease

We have a lease through the Research Foundation for the State University of New York (the “SUNY Foundation”) with respect to Gigafactory New York. Under the lease and a related research and development agreement, we are continuing to designate further buildouts at the facility. We are required to comply with certain covenants, including hiring and cumulative investment targets. This incentive offsets the related lease costs of the facility in our consolidated financial statements included elsewhere in this Annual Report on Form 10-K.

As we temporarily suspended most of our manufacturing operations at Gigafactory New York pursuant to a New York State executive order issued in March 2020 as a result of the COVID-19 pandemic, we were granted a deferral of our obligation to be compliant with our applicable targets through December 31, 2021 in an amendment memorialized in August 2021. As of December 31, 2021, we are in excess of such targets relating to investments and personnel in the State of New York and Buffalo.

Gigafactory Shanghai—Land Use Rights and Economic Benefits

We have an agreement with the local government of Shanghai for land use rights at Gigafactory Shanghai. Under the terms of the arrangement, we are required to meet a cumulative capital expenditure target and an annual tax revenue target starting at the end of 2023. In addition, the Shanghai government has granted to our Gigafactory Shanghai subsidiary certain incentives to be used in connection with eligible capital investments at Gigafactory Shanghai.

### Showing final RAG image caption results from LlamaIndex[¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_multi_modal_tesla_10q/#showing-final-rag-image-caption-results-from-llamaindex)

In \[ \]:

Copied!

print(rag\_response)

print(rag\_response)

The Gigafactory Shanghai in Shanghai, China is a large Tesla factory that produces electric vehicles for the global market. The factory has a white roof and is surrounded by a parking lot filled with numerous cars, including both small and large vehicles. The cars are parked in various positions, some closer to the factory and others further away. This scene gives an impression of a busy and well-organized facility.

Back to top

[Previous LlaVa Demo with LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/multi_modal/llava_demo/)[Next \[Beta\] Multi-modal ReAct Agent](https://docs.llamaindex.ai/en/stable/examples/multi_modal/mm_agent/)

🦙
