Title: Web - LlamaIndex

URL Source: https://docs.llamaindex.ai/en/stable/api_reference/readers/web/

Markdown Content:
Skip to content
LlamaIndex
Web
Initializing search
LlamaIndex
Home
Home
High-Level Concepts
Installation and Setup
How to read these docs
Starter Examples
Starter Examples
Starter Tutorial (OpenAI)
Starter Tutorial (Local Models)
Discover LlamaIndex Video Series
Frequently Asked Questions (FAQ)
Starter Tools
Starter Tools
RAG CLI
Learn
Learn
Using LLMs
Building a RAG pipeline
Building a RAG pipeline
Loading & Ingestion
Loading & Ingestion
Loading Data (Ingestion)
LlamaHub
Indexing & Embedding
Storing
Querying
Building an agent
Building an agent
Building a basic agent
Agents with local models
Adding RAG to an agent
Enhancing with LlamaParse
Memory
Adding other tools
Tracing and Debugging
Evaluating
Evaluating
Evaluating
Cost Analysis
Cost Analysis
Usage Pattern
Putting it all Together
Putting it all Together
Full-stack web application
Full-stack web application
A Guide to Building a Full-Stack Web App with LLamaIndex
A Guide to Building a Full-Stack LlamaIndex Web App with Delphic
Q&A Patterns
Q&A Patterns
A Guide to Extracting Terms and Definitions
Chatbots
Chatbots
How to Build a Chatbot
Structured data
Structured data
Agents
Use Cases
Use Cases
Prompting
Question-Answering (RAG)
Chatbots
Structured Data Extraction
Agents
Multi-Modal Applications
Fine-Tuning
Examples
Examples
Agents
Agents
ðŸ’¬ðŸ¤– How to Build a Chatbot
GPT Builder Demo
Building a Multi-PDF Agent using Query Pipelines and HyDE
Step-wise, Controllable Agents
Controllable Agents for RAG
Building an Agent around a Query Pipeline
Agentic rag using vertex ai
Agentic rag with llamaindex and vertexai managed index
Function Calling Anthropic Agent
Function Calling AWS Bedrock Converse Agent
Chain-of-Abstraction LlamaPack
Building a Custom Agent
DashScope Agent Tutorial
Introspective Agents: Performing Tasks With Reflection
Language Agent Tree Search
LLM Compiler Agent Cookbook
Simple Composable Memory
Vector Memory
Function Calling Mistral Agent
Multi-Document Agents (V1)
Multi-Document Agents
Build your own OpenAI Agent
Context-Augmented OpenAI Agent
OpenAI Agent Workarounds for Lengthy Tool Descriptions
Single-Turn Multi-Function Calling OpenAI Agents
OpenAI Agent + Query Engine Experimental Cookbook
OpenAI Agent Query Planning
Retrieval-Augmented OpenAI Agent
OpenAI Agent with Tool Call Parser
OpenAI Agent with Query Engine Tools
OpenAI Assistant Agent
OpenAI Assistant Advanced Retrieval Cookbook
OpenAI agent: specifying a forced function call
Benchmarking OpenAI Retrieval API (through Assistant Agent)
ReAct Agent - A Simple Intro with Calculator Tools
ReAct Agent with Query Engine (RAG) Tools
Controlling Agent Reasoning Loop with Return Direct Tools
Structured Planning Agent
Callbacks
Callbacks
Aim Callback
HoneyHive LlamaIndex Tracer
Langfuse Callback Handler
Llama Debug Handler
OpenInference Callback Handler + Arize Phoenix
Observability with OpenLLMetry
PromptLayer Handler
Token Counting Handler
UpTrain Callback Handler
Wandb Callback Handler
Chat Engines
Chat Engines
Chat Engine - Best Mode
Chat Engine - Condense Plus Context Mode
Chat Engine - Condense Question Mode
Chat Engine - Context Mode
Chat Engine - OpenAI Agent Mode
Chat Engine with a Personality âœ¨
Chat Engine - ReAct Agent Mode
Chat Engine - Simple Mode REPL
Cookbooks
Cookbooks
Anthropic Haiku Cookbook
Codestral from MistralAI Cookbook
Cohere init8 and binary Embeddings Retrieval Evaluation
CrewAI + LlamaIndex Cookbook
Llama3 Cookbook
Llama3 Cookbook with Groq
Llama3 Cookbook with Ollama and Replicate
MistralAI Cookbook
mixedbread Rerank Cookbook
Prometheus-2 Cookbook
Customization
Customization
Azure OpenAI
ChatGPT
HuggingFace LLM - Camel-5b
HuggingFace LLM - StableLM
Chat Prompts Customization
Completion Prompts Customization
Streaming
Streaming for Chat Engine - Condense Question Mode
Data Connectors
Data Connectors
Chroma Reader
DashVector Reader
Database Reader
DeepLake Reader
Discord Reader
Faiss Reader
Github Repo Reader
Google Chat Reader Test
Google Docs Reader
Google Drive Reader
Google Maps Text Search Reader
Google Sheets Reader
Make Reader
Mbox Reader
MilvusReader
MongoDB Reader
MyScale Reader
Notion Reader
Obsidian Reader
Pathway Reader
Pinecone Reader
Psychic Reader
Qdrant Reader
Slack Reader
Twitter Reader
Weaviate Reader
Web Page Reader
Deplot Reader Demo
HTML Tag Reader
Simple Directory Reader
Parallel Processing SimpleDirectoryReader
Simple Directory Reader over a Remote FileSystem
Discover LlamaIndex
Discover LlamaIndex
Discord Thread Management
Docstores
Docstores
Demo: Azure Table Storage as a Docstore
Docstore Demo
Dynamo DB Docstore Demo
Firestore Demo
MongoDB Demo
Redis Docstore+Index Store Demo
Embeddings
Embeddings
Anyscale Embeddings
LangChain Embeddings
OpenAI Embeddings
Aleph Alpha Embeddings
Bedrock Embeddings
Embeddings with Clarifai
Cloudflare Workers AI Embeddings
CohereAI Embeddings
Custom Embeddings
Dashscope embeddings
Databricks Embeddings
Deepinfra
Elasticsearch Embeddings
Qdrant FastEmbed Embeddings
Fireworks Embeddings
Google Gemini Embeddings
Google PaLM Embeddings
Gradient Embeddings
Local Embeddings with HuggingFace
IBM watsonx.ai
Local Embeddings with IPEX-LLM on Intel CPU
Local Embeddings with IPEX-LLM on Intel GPU
Optimized BGE Embedding Model using IntelÂ® Extension for Transformers
Jina 8K Context Window Embeddings
Jina Embeddings
Llamafile Embeddings
LLMRails Embeddings
MistralAI Embeddings
Mixedbread AI Embeddings
Nomic Embedding
NVIDIA NIMs
Oracle Cloud Infrastructure Generative AI
OctoAI Embeddings
Ollama Embeddings
Local Embeddings with OpenVINO
Optimized Embedding Model using Optimum-Intel
PremAI Embeddings
Interacting with Embeddings deployed in Amazon SageMaker Endpoint with LlamaIndex
Text Embedding Inference
Together AI Embeddings
Upstage Embeddings
Voyage Embeddings
Evaluation
Evaluation
BEIR Out of Domain Benchmark
ðŸš€ RAG/LLM Evaluators - DeepEval
HotpotQADistractor Demo
QuestionGeneration
Self Correcting Query Engines - Evaluation & Retry
Tonic Validate Evaluators
How to use UpTrain with LlamaIndex
Answer Relevancy and Context Relevancy Evaluations
BatchEvalRunner - Running Multiple Evaluations
Correctness Evaluator
Faithfulness Evaluator
Guideline Evaluator
Benchmarking LLM Evaluators On The MT-Bench Human Judgement LabelledPairwiseEvaluatorDataset
Benchmarking LLM Evaluators On A Mini MT-Bench (Single Grading) LabelledEvaluatorDataset
Evaluating Multi-Modal RAG
Pairwise Evaluator
Evaluation using Prometheus model
Relevancy Evaluator
Retrieval Evaluation
Embedding Similarity Evaluator
Finetuning
Finetuning
How to Finetune a cross-encoder using LLamaIndex
Finetune Embeddings
Finetuning an Adapter on Top of any Black-Box Embedding Model
Fine Tuning Nous-Hermes-2 With Gradient and LlamaIndex
Fine Tuning Llama2 for Better Structured Outputs With Gradient and LlamaIndex
Fine Tuning for Text-to-SQL With Gradient and LlamaIndex
Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)
Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)
Fine Tuning MistralAI models using Finetuning API
Fine Tuning GPT-3.5-Turbo
Fine Tuning with Function Calling
Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought
Custom Cohere Reranker
Router Fine-tuning
Ingestion
Ingestion
Advanced Ingestion Pipeline
Async Ingestion Pipeline + Metadata Extraction
Ingestion Pipeline + Document Management
Building a Live RAG Pipeline over Google Drive Files
Parallelizing Ingestion Pipeline
Redis Ingestion Pipeline
LLMs
LLMs
AI21
Aleph Alpha
Anthropic
Anyscale
Azure OpenAI
Bedrock
Bedrock Converse
Clarifai LLM
Cleanlab Trustworthy Language Model
Cohere
DashScope LLMS
DataBricks
DeepInfra
EverlyAI
Fireworks
Fireworks Function Calling Cookbook
Friendli
Gemini
Gradient Base Model
Gradient Model Adapter
Groq
Hugging Face LLMs
IBM watsonx.ai
IPEX-LLM on Intel CPU
IPEX-LLM on Intel GPU
Konko
Langchain
LiteLLM
Replicate - Llama 2 13B
LlamaCPP
ðŸ¦™ x ðŸ¦™ Rap Battle
Llama API
llamafile
LLM Predictor
LM Studio
LocalAI
Maritalk
MistralRS LLM
MistralAI
None
ModelScope LLMS
Monster API <> LLamaIndex
MyMagic AI LLM
Neutrino AI
NVIDIA NIMs
NVIDIA NIMs
Nvidia TensorRT-LLM
Nvidia Triton
Oracle Cloud Infrastructure Generative AI
OctoAI
Ollama - Llama 3
Ollama - Gemma
OpenAI
OpenAI JSON Mode vs. Function Calling for Data Extraction
OpenLLM
OpenRouter
OpenVINO LLMs
Optimum Intel LLMs optimized with IPEX backend
PaLM
Perplexity
Portkey
Predibase
PremAI LlamaIndex
Client of Baidu Intelligent Cloud's Qianfan LLM Platform
RunGPT
Interacting with LLM deployed in Amazon SageMaker Endpoint with LlamaIndex
Solar LLM
Together AI LLM
Unify
Upstage
Vertex AI
Replicate - Vicuna 13B
vLLM
Xorbits Inference
Yi
Llama Datasets
Llama Datasets
Downloading a LlamaDataset from LlamaHub
Benchmarking RAG Pipelines With A LabelledRagDatatset
LlamaDataset Submission Template Notebook
Contributing a LlamaDataset To LlamaHub
Llama Hub
Llama Hub
LlamaHub Demostration
Ollama Llama Pack Example
Llama Pack - Resume Screener ðŸ“„
Llama Packs Example
Low Level
Low Level
Building Evaluation from Scratch
Building an Advanced Fusion Retriever from Scratch
Building Data Ingestion from Scratch
Building RAG from Scratch (Open-source only!)
Building Response Synthesis from Scratch
Building Retrieval from Scratch
Building a Router from Scratch
Building a (Very Simple) Vector Store from Scratch
Managed Indexes
Managed Indexes
Google Generative Language Semantic Retriever
PostgresML Managed Index
Google Cloud LlamaIndex on Vertex AI for RAG
Semantic Retriever Benchmark
Vectara Managed Index
Managed Index with Zilliz Cloud Pipelines
Metadata Extractors
Metadata Extractors
Entity Metadata Extraction
Metadata Extraction and Augmentation w/ Marvin
Extracting Metadata for Better Document Indexing and Understanding
Automated Metadata Extraction for Better Retrieval + Synthesis
Pydantic Extractor
Multi-Modal
Multi-Modal
Chroma Multi-Modal Demo with LlamaIndex
Multi-Modal LLM using Anthropic model for image reasoning
Multi-Modal LLM using Azure OpenAI GPT-4V model for image reasoning
Multi-Modal LLM using DashScope qwen-vl model for image reasoning
Multi-Modal LLM using Google's Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex
Multimodal Structured Outputs: GPT-4o vs. Other GPT-4 Variants
GPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.
Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever
Image to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V
LlaVa Demo with LlamaIndex
Retrieval-Augmented Image Captioning
[Beta] Multi-modal ReAct Agent
Multi-Modal GPT4V Pydantic Program
Multi-Modal RAG using Nomic Embed and Anthropic.
Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles
Multimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore
Multimodal Ollama Cookbook
Multi-Modal LLM using OpenAI GPT-4V model for image reasoning
Multi-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning
Semi-structured Image Retrieval
Multi-Tenancy
Multi-Tenancy
Multi-Tenancy RAG with LlamaIndex
Node Parsers & Text Splitters
Node Parsers & Text Splitters
Semantic Chunker
Semantic double merging chunking
Node Postprocessors
Node Postprocessors
Cohere Rerank
Colbert Rerank
File Based Node Parsers
FlagEmbeddingReranker
Jina Rerank
LLM Reranker Demonstration (Great Gatsby)
LLM Reranker Demonstration (2021 Lyft 10-k)
LongContextReorder
Metadata Replacement + Node Sentence Window
Mixedbread AI Rerank
NVIDIA NIMs
Sentence Embedding OptimizerThis postprocessor optimizes token usage by removing sentences that are not relevant to the query (this is done using embeddings).The percentile cutoff is a measure for using the top percentage of relevant sentences. The threshold cutoff can be specified instead, which uses a raw similarity cutoff for picking which sentences to keep.
PII Masking
Forward/Backward Augmentation
Recency Filtering
SentenceTransformerRerank
Time-Weighted Rerank
VoyageAI Rerank
OpenVINO Rerank
RankGPT Reranker Demonstration (Van Gogh Wiki)
RankLLM Reranker Demonstration (Van Gogh Wiki)
Object Stores
Object Stores
The ObjectIndex Class
Output Parsers
Output Parsers
Guardrails Output Parsing
Langchain Output Parsing
DataFrame Structured Data Extraction
Evaporate Demo
Function Calling Program for Structured Extraction
Guidance Pydantic Program
Guidance for Sub-Question Query Engine
LLM Pydantic Program
LM Format Enforcer Pydantic Program
LM Format Enforcer Regular Expression Generation
OpenAI Pydantic Program
OpenAI function calling for Sub-Question Query Engine
Param Optimizer
Param Optimizer
[WIP] Hyperparameter Optimization for RAG
Prompts
Prompts
Advanced Prompt Techniques (Variable Mappings, Functions)
EmotionPrompt in RAG
Accessing/Customizing Prompts within Higher-Level Modules
"Optimization by Prompting" for RAG
Prompt Engineering for RAG
Property Graph
Property Graph
Using a Property Graph Store
Property Graph Construction with Predefined Schemas
Property Graph Index
Defining a Custom Property Graph Retriever
Neo4j Property Graph Index
Query Engines
Query Engines
Retriever Query Engine with Custom Retrievers - Simple Hybrid Search
JSONalyze Query Engine
Joint QA Summary Query Engine
Retriever Router Query Engine
Router Query Engine
SQL Auto Vector Query Engine
SQL Join Query Engine
SQL Router Query Engine
CitationQueryEngine
Cogniswitch query engine
Defining a Custom Query Engine
Ensemble Query Engine Guide
FLARE Query Engine
JSON Query Engine
Knowledge Graph Query Engine
Knowledge Graph RAG Query Engine
Structured Hierarchical Retrieval
Pandas Query Engine
Recursive Retriever + Query Engine Demo
[Beta] Text-to-SQL with PGVector
Query Engine with Pydantic Outputs
Recursive Retriever + Document Agents
Joint Tabular/Semantic QA over Tesla 10K
Sub Question Query Engine
Query Pipeline
Query Pipeline
An Introduction to LlamaIndex Query Pipelines
Query Pipeline with Async/Parallel Execution
Query Pipeline Chat Engine
Query Pipeline over Pandas DataFrames
Query Pipeline with Routing
Query Pipeline for Advanced Text-to-SQL
Query Transformations
Query Transformations
HyDE Query Transform
Multi-Step Query Engine
Query Transform Cookbook
Response Synthesizers
Response Synthesizers
Pydantic Tree Summarize
Stress-Testing Long Context LLMs with a Recall Task
Pydantic Tree Summarize
Refine
Refine with Structured Answer Filtering
Tree Summarize
Retrievers
Retrievers
Auto Merging Retriever
Comparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)
Bedrock (Knowledge Bases)
BM25 Retriever
Composable Objects
Activeloop Deep Memory
Ensemble Retrieval Guide
Chunk + Document Hybrid Retrieval with Long-Context Embeddings (Together.ai)
Pathway Retriever
Reciprocal Rerank Fusion Retriever
Recursive Retriever + Node References + Braintrust
Recursive Retriever + Node References
Relative Score Fusion and Distribution-Based Score Fusion
Router Retriever
Simple Fusion Retriever
Auto-Retrieval from a Vectara Index
VideoDB Retriever
You.com Retriever
Tools
Tools
OnDemandLoaderTool Tutorial
Azure Code Interpreter Tool Spec
Cassandra Database Tools
Evaluation Query Engine Tool
Transforms
Transforms
Transforms Evaluation
Use Cases
Use Cases
10K Analysis
10Q Analysis
Email Data Extraction
Github Issue Analysis
Vector Stores
Vector Stores
AWSDocDBDemo
Alibaba Cloud OpenSearch Vector Store
Amazon Neptune - Neptune Analytics vector store
AnalyticDB
Astra DB
Simple Vector Store - Async Index Creation
Awadb Vector Store
Azure AI Search
Azure CosmosDB MongoDB Vector Store
Bagel Vector Store
Bagel Network
Baidu VectorDB
Cassandra Vector Store
Chroma + Fireworks + Nomic with Matryoshka embedding
Chroma
ClickHouse Vector Store
CouchbaseVectorStoreDemo
DashVector Vector Store
Databricks Vector Search
Deep Lake Vector Store Quickstart
DocArray Hnsw Vector Store
DocArray InMemory Vector Store
DuckDB
Elasticsearch Vector Store
Elasticsearch
Epsilla Vector Store
Faiss Vector Store
Firestore Vector Store
Hologres
Jaguar Vector Store
Advanced RAG with temporal filters using LlamaIndex and KDB.AI vector store
LanceDB Vector Store
Lantern Vector Store (auto-retriever)
Lantern Vector Store
Metal Vector Store
Milvus Vector Store With Hybrid Retrieval
Milvus Vector Store
MilvusOperatorFunctionDemo
MongoDBAtlasVectorSearch
now make sure you create the search index with the right name here
MongoDBAtlasVectorSearchRAGOpenAI
MyScale Vector Store
Neo4j vector store
Opensearch Vector Store
pgvecto.rs
Pinecone Vector Store - Hybrid Search
Pinecone Vector Store
Qdrant Vector Store
Qdrant Vector Store - Metadata Filter
Qdrant Vector Store - Default Qdrant Filters
Redis Vector Store
Relyt
Rockset Vector Store
Simple Vector Store
Local Llama2 + VectorStoreIndex
Llama2 + VectorStoreIndex
Simple Vector Stores - Maximum Marginal Relevance Retrieval
S3/R2 Storage
Supabase Vector Store
Tair Vector Store
Tencent Cloud VectorDB
TiDB Vector Store
Timescale Vector Store (PostgreSQL)
txtai Vector Store
Typesense Vector Store
Upstash Vector Store
VearchDemo
Google Vertex AI Vector Search
Vespa Vector Store demo
Weaviate Vector Store - Hybrid Search
Weaviate Vector Store
Auto-Retrieval from a Weaviate Vector Database
Weaviate Vector Store Metadata Filter
Zep Vector Store
Auto-Retrieval from a Vector Database
Chroma Vector Store
Auto-Retrieval from a Vector Database
Guide: Using Vector Store Index with Existing Pinecone Vector Store
Guide: Using Vector Store Index with Existing Weaviate Vector Store
Neo4j Vector Store - Metadata Filter
A Simple to Advanced Guide with Auto-Retrieval (with Pinecone + Arize Phoenix)
Pinecone Vector Store - Metadata Filter
Postgres Vector Store
Hybrid Search with Qdrant BM42
Qdrant Hybrid Search
Component Guides
Component Guides
Models
Models
LLMs
LLMs
Using LLMs
Standalone Usage
Customizing LLMs
Available LLM Integrations
Embeddings
Multi Modal
Prompts
Prompts
Usage pattern
Loading
Loading
Documents and Nodes
Documents and Nodes
Using Documents
Using Nodes
Metadata Extraction
SimpleDirectoryReader
Data Connectors
Data Connectors
Usage Pattern
LlamaParse
Module Guides
Node Parsers / Text Splitters
Node Parsers / Text Splitters
Node Parser Modules
Ingestion Pipeline
Ingestion Pipeline
Transformations
Indexing
Indexing
Index Guide
Vector Store Index
Property Graph Index
Document Management
LlamaCloud
Metadata Extraction
Modules
Storing
Storing
Vector Stores
Document Stores
Index Stores
Chat Stores
Key-Value Stores
Persisting & Loading Data
Customizing Storage
Querying
Querying
Query Engines
Query Engines
Usage Pattern
Response Modes
Streaming
Module Guides
Supporting Modules
Chat Engines
Chat Engines
Usage Pattern
Module Guides
Retrieval
Retrieval
Retriever Modules
Retriever Modes
Node Postprocessors
Node Postprocessors
Node Postprocessor Modules
Response Synthesis
Response Synthesis
Response Synthesis Modules
Routing
Query Pipelines
Query Pipelines
Usage Pattern
Module Guides
Module Usage
Structured Outputs
Structured Outputs
Output Parsing Modules
Query Engines + Pydantic Outputs
Pydantic Program
Agents
Agents
Usage Pattern
Lower-Level Agent API
Module Guides
Tools
Evaluation
Evaluation
Usage Pattern (Response Evaluation)
Usage Pattern (Retrieval)
Modules
LlamaDatasets
LlamaDatasets
Contributing A LabelledRagDataset
Evaluating With LabelledRagDataset's
Evaluating Evaluators with LabelledEvaluatorDataset's
Observability
Observability
Instrumentation
Settings
Advanced Topics
Advanced Topics
Building Performant RAG Applications for Production
Basic Strategies
Agentic strategies
Retrieval
Retrieval
Advanced Retrieval Strategies
Query Transformations
Evaluation
Evaluation
Component Wise Evaluation
End-to-End Evaluation
Evaluation
Fine-Tuning
Writing Custom Modules
Building RAG from Scratch (Lower-Level)
API Reference
API Reference
Agents
Agents
Coa
Dashscope
Introspective
Lats
Llm compiler
Openai
Openai legacy
React
Callbacks
Callbacks
Agentops
Aim
Argilla
Arize phoenix
Deepeval
Honeyhive
Langfuse
Llama debug
Openinference
Promptlayer
Token counter
Uptrain
Wandb
Chat Engines
Chat Engines
Condense plus context
Condense question
Context
Simple
Embeddings
Embeddings
Adapter
Alephalpha
Anyscale
Azure openai
Bedrock
Clarifai
Clip
Cloudflare workersai
Cohere
Dashscope
Databricks
Deepinfra
Elasticsearch
Fastembed
Fireworks
Gemini
Google
Gradient
Huggingface
Huggingface api
Huggingface itrex
Huggingface openvino
Huggingface optimum
Huggingface optimum intel
Ibm
Instructor
Ipex llm
Jinaai
Langchain
Litellm
Llamafile
Llm rails
Mistralai
Mixedbreadai
Nomic
Nvidia
Oci genai
Octoai
Ollama
Openai
Premai
Sagemaker endpoint
Text embeddings inference
Together
Upstage
Vertex
Voyageai
Evaluation
Evaluation
Answer relevancy
Context relevancy
Correctness
Dataset generation
Faithfullness
Guideline
Metrics
Multi modal
Pairwise comparison
Query response
Response
Retrieval
Semantic similarity
Tonic validate
Indexes
Indexes
Colbert
Dashscope
Document summary
Google
Keyword
Knowledge graph
Llama cloud
Postgresml
Property graph
Summary
Tree
Vectara
Vector
Vertexai
Zilliz
Ingestion
Ingestion
Instrumentation
Instrumentation
Event handlers
Event types
Span handlers
Span types
LLMs
LLMs
None
Ai21
Alephalpha
Anthropic
Anyscale
Azure openai
Bedrock
Bedrock converse
Clarifai
Cleanlab
Cohere
Custom llm
Dashscope
Databricks
Deepinfra
Everlyai
Fireworks
Friendli
Gemini
Gradient
Groq
Huggingface
Huggingface api
Ibm
Ipex llm
Konko
Langchain
Litellm
Llama api
Llama cpp
Llamafile
Lmstudio
Localai
Maritalk
Mistral rs
Mistralai
Mlx
Modelscope
Monsterapi
Mymagic
Neutrino
Nvidia
Nvidia tensorrt
Nvidia triton
Oci genai
Octoai
Ollama
Openai
Openai like
Openllm
Openrouter
Openvino
Optimum intel
Palm
Perplexity
Portkey
Predibase
Premai
Qianfan
Replicate
Rungpt
Sagemaker endpoint
Solar
Text generation inference
Together
Unify
Upstage
Vertex
Vllm
Xinference
Yi
You
Llama Datasets
Llama Datasets
Llama Packs
Llama Packs
Agent search retriever
Agents coa
Agents lats
Agents llm compiler
Amazon product extraction
Arize phoenix query engine
Auto merging retriever
Chroma autoretrieval
Code hierarchy
Cogniswitch agent
Cohere citation chat
Corrective rag
Deeplake deepmemory retriever
Deeplake multimodal retrieval
Dense x retrieval
Diff private simple dataset
Docugami kg rag
Evaluator benchmarker
Finchat
Fusion retriever
Fuzzy citation
Gmail openai agent
Gradio agent chat
Gradio react agent chatbot
Infer retrieve rerank
Koda retriever
Llama dataset metadata
Llama guard moderator
Llava completion
Mixture of agents
Multi document agents
Multi tenancy rag
Multidoc autoretrieval
Nebulagraph query engine
Neo4j query engine
Node parser semantic chunking
Ollama query engine
Panel chatbot
Query understanding agent
Raft dataset
Rag cli local
Rag evaluator
Rag fusion query pipeline
Ragatouille retriever
Raptor
Recursive retriever
Redis ingestion pipeline
Resume screener
Retry engine weaviate
Searchain
Secgpt
Self discover
Self rag
Sentence window retriever
Snowflake query engine
Stock market data query engine
Streamlit chatbot
Sub question weaviate
Subdoc summary
Tables
Timescale vector autoretrieval
Trulens eval packs
Vanna
Vectara rag
Voyage query engine
Zenguard
Zephyr query engine
Memory
Memory
Chat memory buffer
Simple composable memory
Vector memory
Metadata Extractors
Metadata Extractors
Entity
Keyword
Marvin
Pydantic
Question
Summary
Title
Multi-Modal LLMs
Multi-Modal LLMs
Anthropic
Azure openai
Dashscope
Gemini
Ollama
Openai
Replicate
Node Parsers & Text Splitters
Node Parsers & Text Splitters
Dashscope
Code
Hierarchical
Html
Json
Langchain
Markdown
Markdown element
Semantic splitter
Sentence splitter
Sentence window
Token text splitter
Unstructured element
Node Postprocessors
Node Postprocessors
NER PII
PII
Auto prev next
Cohere rerank
Colbert rerank
Dashscope rerank
Embedding recency
Fixed recency
Flag embedding reranker
Jinaai rerank
Keyword
Llm rerank
Long context reorder
Longllmlingua
Metadata replacement
Mixedbreadai rerank
Nvidia rerank
Openvino rerank
Presidio
Prev next
Rankgpt rerank
Rankllm rerank
Sbert rerank
Sentence optimizer
Similarity
Time weighted
Voyageai rerank
Object Stores
Object Stores
Output Parsers
Output Parsers
Guardrails
Langchain
Pydantic
Selection
Programs
Programs
Evaporate
Guidance
Llm text completion
Lmformatenforcer
Multi modal
Openai
Prompts
Prompts
Query Engines
Query Engines
FLARE
JSONalayze
NL SQL table
PGVector SQL
SQL join
SQL table retriever
Citation
Cogniswitch
Custom
Knowledge graph
Multi step
Pandas
Retriever
Retriever router
Retry
Router
Simple multi modal
Sub question
Tool retriever router
Transform
Query Pipeline
Query Pipeline
Agent
Arg pack
Custom
Function
Input
Llm
Multi modal
Object
Output parser
Postprocessor
Prompt
Query engine
Query transform
Retriever
Router
Synthesizer
Tool runner
Question Generators
Question Generators
Guidance
Llm question gen
Openai
Readers
Readers
Agent search
Airbyte cdk
Airbyte gong
Airbyte hubspot
Airbyte salesforce
Airbyte shopify
Airbyte stripe
Airbyte typeform
Airbyte zendesk support
Airtable
Apify
Arango db
Arxiv
Asana
Assemblyai
Astra db
Athena
Awadb
Azcognitive search
Azstorage blob
Azure devops
Bagel
Bilibili
Bitbucket
Boarddocs
Chatgpt plugin
Chroma
Clickhouse
Confluence
Couchbase
Couchdb
Dad jokes
Dashscope
Dashvector
Database
Deeplake
Discord
Docstring walker
Docugami
Earnings call transcript
Elasticsearch
Faiss
Feedly rss
Feishu docs
Feishu wiki
File
Firebase realtimedb
Firestore
Gcs
Genius
Github
Google
Gpt repo
Graphdb cypher
Graphql
Guru
Hatena blog
Hive
Hubspot
Huggingface fs
Hwp
Iceberg
Imdb review
Intercom
Jaguar
Jira
Joplin
Json
Kaltura esearch
Kibela
Lilac
Linear
Llama parse
Macrometa gdn
Make com
Mangadex
Mangoapps guides
Maps
Mbox
Memos
Metal
Microsoft onedrive
Microsoft outlook
Microsoft sharepoint
Milvus
Minio
Mondaydotcom
Mongodb
Myscale
Notion
Nougat ocr
Obsidian
Openalex
Openapi
Opendal
Opensearch
Pandas ai
Papers
Patentsview
Pathway
Pdb
Pdf marker
Pdf table
Pebblo
None
Preprocess
Psychic
Qdrant
Rayyan
Readme
Readwise
Reddit
Remote
Remote depth
S3
Sec filings
Semanticscholar
Simple directory reader
Singlestore
Slack
Smart pdf loader
Snowflake
Snscrape twitter
Spotify
Stackoverflow
Steamship
String iterable
Stripe docs
Structured data
Telegram
Toggl
Trello
Twitter
Txtai
Upstage
Weather
Weaviate
Web
Whatsapp
Wikipedia
Wordlift
Wordpress
Youtube metadata
Youtube transcript
Zendesk
Zep
Zulip
Response Synthesizers
Response Synthesizers
Accumulate
Compact accumulate
Compact and refine
Generation
Google
Refine
Simple summarize
Tree summarize
Retrievers
Retrievers
Auto merging
Bedrock
Bm25
Duckdb retriever
Keyword
Knowledge graph
Mongodb atlas bm25 retriever
Pathway
Query fusion
Recursive
Router
Sql
Summary
Transform
Tree
Vector
Videodb
You
Schema
Schema
Storage
Storage
Chat Store
Chat Store
Azure
Redis
Simple
Docstore
Docstore
Azure
Dynamodb
Elasticsearch
Firestore
Mongodb
Postgres
Redis
Simple
Graph Stores
Graph Stores
Falkordb
Kuzu
Nebula
Neo4j
Neptune
Simple
Tidb
Index Store
Index Store
Azure
Dynamodb
Elasticsearch
Firestore
Mongodb
Postgres
Redis
Simple
Kvstore
Kvstore
Azure
Dynamodb
Elasticsearch
Firestore
Mongodb
Postgres
Redis
S3
Simple
Storage
Storage
Storage context
Vector Store
Vector Store
Alibabacloud opensearch
Analyticdb
Astra db
Awadb
Awsdocdb
Azureaisearch
Azurecosmosmongo
Bagel
Baiduvectordb
Cassandra
Chatgpt plugin
Chroma
Clickhouse
Couchbase
Dashvector
Databricks
Deeplake
Docarray
Duckdb
Dynamodb
Elasticsearch
Epsilla
Faiss
Firestore
Google
Hologres
Jaguar
Kdbai
Lancedb
Lantern
Metal
Milvus
Mongodb
Myscale
Neo4jvector
Neptune
Opensearch
Pgvecto rs
Pinecone
Postgres
Qdrant
Redis
Relyt
Rocksetdb
Simple
Singlestoredb
Supabase
Tair
Tencentvectordb
Tidbvector
Timescalevector
Txtai
Typesense
Upstash
Vearch
Vertexaivectorsearch
Vespa
Weaviate
Wordlift
Zep
Tools
Tools
Arxiv
Azure code interpreter
Azure cv
Azure speech
Azure translate
Bing search
Brave search
Cassandra
Chatgpt plugin
Code interpreter
Cogniswitch
Database
Duckduckgo
Exa
Finance
Function
Google
Graphql
Ionic shopping
Jina
Load and search
Metaphor
Multion
Neo4j
Notion
Ondemand loader
Openai
Openapi
Passio nutrition ai
Playgrounds
Python file
Query engine
Query plan
Requests
Retriever
Salesforce
Shopify
Slack
Tavily research
Text to image
Tool spec
Vector db
Waii
Weather
Wikipedia
Wolfram alpha
Yahoo finance
Yelp
Zapier
Open-Source Community
Open-Source Community
Integrations
Full Stack Projects
Community FAQ
Community FAQ
Chat Engines
Documents and Nodes
Embeddings
Large Language Models
Query Engines
Vector Database
Contributing
Contributing
Code
Docs
Changelog
Presentations
Upgrading to v0.10.x
Deprecated Terms
LlamaCloud
LlamaCloud
LlamaParse
Table of contents
AsyncWebPageReader
aload_data
load_data
BeautifulSoupWebReader
class_name
load_data
BrowserbaseWebReader
lazy_load_data
FireCrawlWebReader
load_data
KnowledgeBaseWebReader
load_data
scrape_article
get_article_urls
MainContentExtractorReader
load_data
NewsArticleReader
load_data
ReadabilityWebPageReader
async_load_data
scrape_page
RssNewsReader
load_data
RssReader
load_data
ScrapflyReader
load_data
SimpleWebPageReader
load_data
SitemapReader
TrafilaturaWebReader
class_name
load_data
UnstructuredURLLoader
load_data
WholeSiteReader
setup_driver
load_data
Web

Init file.

AsyncWebPageReader #

Bases: BaseReader

Asynchronous web page reader.

Reads pages from the web asynchronously.

Parameters:

Name	Type	Description	Default
html_to_text	bool	

Whether to convert HTML to text. Requires html2text package.

	False
limit	int	

Maximum number of concurrent requests.

	10
dedupe	bool	

to deduplicate urls if there is exact-match within given list

	True
fail_on_error	bool	

if requested url does not return status code 200 the routine will raise an ValueError

	False
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/async_web/base.py
aload_data async #
aload_data(urls: List[str]) -> List[Document]


Load data from the input urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/async_web/base.py
load_data #
load_data(urls: List[str]) -> List[Document]


Load data from the input urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/async_web/base.py
BeautifulSoupWebReader #

Bases: BasePydanticReader

BeautifulSoup web page reader.

Reads pages from the web. Requires the bs4 and urllib packages.

Parameters:

Name	Type	Description	Default
website_extractor	Optional[Dict[str, Callable]]	

A mapping of website hostname (e.g. google.com) to a function that specifies how to extract text from the BeautifulSoup obj. See DEFAULT_WEBSITE_EXTRACTOR.

	None
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/beautiful_soup_web/base.py
class_name classmethod #
class_name() -> str


Get the name identifier of the class.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/beautiful_soup_web/base.py
load_data #
load_data(urls: List[str], custom_hostname: Optional[str] = None, include_url_in_text: Optional[bool] = True) -> List[Document]


Load data from the urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required
custom_hostname	Optional[str]	

Force a certain hostname in the case a website is displayed under custom URLs (e.g. Substack blogs)

	None
include_url_in_text	Optional[bool]	

Include the reference url in the text of the document

	True

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/beautiful_soup_web/base.py
BrowserbaseWebReader #

Bases: BaseReader

BrowserbaseWebReader.

Load pre-rendered web pages using a headless browser hosted on Browserbase. Depends on browserbase package. Get your API key from https://browserbase.com

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/browserbase_web/base.py
lazy_load_data #
lazy_load_data(urls: Sequence[str], text_content: bool = False, session_id: Optional[str] = None, proxy: Optional[bool] = None) -> Iterator[Document]


Load pages from URLs.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/browserbase_web/base.py
FireCrawlWebReader #

Bases: BasePydanticReader

turn a url to llm accessible markdown with Firecrawl.dev.

Args: api_key: The Firecrawl API key. api_url: url to be passed to FirecrawlApp for local deployment url: The url to be crawled (or) mode: The mode to run the loader in. Default is "crawl". Options include "scrape" (single url) and "crawl" (all accessible sub pages). params: The parameters to pass to the Firecrawl API. Examples include crawlerOptions. For more details, visit: https://github.com/mendableai/firecrawl-py

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/firecrawl_web/base.py
load_data #
load_data(url: Optional[str] = None, query: Optional[str] = None) -> List[Document]


Load data from the input directory.

Parameters:

Name	Type	Description	Default
url	Optional[str]	

URL to scrape or crawl.

	None
query	Optional[str]	

Query to search for.

	None

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Raises:

Type	Description
ValueError	

If neither or both url and query are provided.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/firecrawl_web/base.py
KnowledgeBaseWebReader #

Bases: BaseReader

Knowledge base reader.

Crawls and reads articles from a knowledge base/help center with Playwright. Tested on Zendesk and Intercom CMS, may work on others. Can be run in headless mode but it may be blocked by Cloudflare. Run it headed to be safe. Times out occasionally, just increase the default time out if it does. Requires the playwright package.

Parameters:

Name	Type	Description	Default
root_url	str	

the base url of the knowledge base, with no trailing slash e.g. 'https://support.intercom.com'

	required
link_selectors	List[str]	

list of css selectors to find links to articles while crawling e.g. ['.article-list a', '.article-list a']

	required
article_path	str	

the url path of articles on this domain so the crawler knows when to stop e.g. '/articles'

	required
title_selector	Optional[str]	

css selector to find the title of the article e.g. '.article-title'

	None
subtitle_selector	Optional[str]	

css selector to find the subtitle/description of the article e.g. '.article-subtitle'

	None
body_selector	Optional[str]	

css selector to find the body of the article e.g. '.article-body'

	None
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py
load_data #
load_data() -> List[Document]


Load data from the knowledge base.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py
scrape_article #
scrape_article(browser: Any, url: str) -> Dict[str, str]


Scrape a single article url.

Parameters:

Name	Type	Description	Default
browser	Any	

a Playwright Chromium browser.

	required
url	str	

URL of the article to scrape.

	required

Returns:

Type	Description
Dict[str, str]	

Dict[str, str]: a mapping of article attributes to their values.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py
get_article_urls #
get_article_urls(browser: Any, root_url: str, current_url: str) -> List[str]


Recursively crawl through the knowledge base to find a list of articles.

Parameters:

Name	Type	Description	Default
browser	Any	

a Playwright Chromium browser.

	required
root_url	str	

root URL of the knowledge base.

	required
current_url	str	

current URL that is being crawled.

	required

Returns:

Type	Description
List[str]	

List[str]: a list of URLs of found articles.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py
MainContentExtractorReader #

Bases: BaseReader

MainContentExtractor web page reader.

Reads pages from the web.

Parameters:

Name	Type	Description	Default
text_format	str	

The format of the text. Defaults to "markdown". Requires MainContentExtractor package.

	'markdown'
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/main_content_extractor/base.py
load_data #
load_data(urls: List[str]) -> List[Document]


Load data from the input directory.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/main_content_extractor/base.py
NewsArticleReader #

Bases: BaseReader

Simple news article reader.

Reads news articles from the web and parses them using the newspaper library.

Parameters:

Name	Type	Description	Default
text_mode	bool	

Whether to load a text version or HTML version of the content (default=True).

	True
use_nlp	bool	

Whether to use NLP to extract additional summary and keywords (default=True).

	True
newspaper_kwargs	Any	

Additional keyword arguments to pass to newspaper.Article. See https://newspaper.readthedocs.io/en/latest/user_guide/quickstart.html#article

	{}
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/news/base.py
load_data #
load_data(urls: List[str]) -> List[Document]


Load data from the list of news article urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to load news articles.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/news/base.py
ReadabilityWebPageReader #

Bases: BaseReader

Readability Webpage Loader.

Extracting relevant information from a fully rendered web page. During the processing, it is always assumed that web pages used as data sources contain textual content.

Load the page and wait for it rendered. (playwright)
Inject Readability.js to extract the main content.

Parameters:

Name	Type	Description	Default
proxy	Optional[str]	

Proxy server. Defaults to None.

	None
wait_until	Optional[Literal['commit', 'domcontentloaded', 'load', 'networkidle']]	

Wait until the page is loaded. Defaults to "domcontentloaded".

	'domcontentloaded'
text_splitter	TextSplitter	

Text splitter. Defaults to None.

	None
normalizer	Optional[Callable[[str], str]]	

Text normalizer. Defaults to nfkc_normalize.

	required
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/readability_web/base.py
async_load_data async #
async_load_data(url: str) -> List[Document]


Render and load data content from url.

Parameters:

Name	Type	Description	Default
url	str	

URL to scrape.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/readability_web/base.py
scrape_page async #
scrape_page(browser: Browser, url: str) -> Dict[str, str]


Scrape a single article url.

Parameters:

Name	Type	Description	Default
browser	Any	

a Playwright Chromium browser.

	required
url	str	

URL of the article to scrape.

	required

Returns:

Name	Type	Description
Ref	Dict[str, str]	

https://github.com/mozilla/readability


title	Dict[str, str]	

article title;


content	Dict[str, str]	

HTML string of processed article content;


textContent	Dict[str, str]	

text content of the article, with all the HTML tags removed;


length	Dict[str, str]	

length of an article, in characters;


excerpt	Dict[str, str]	

article description, or short excerpt from the content;


byline	Dict[str, str]	

author metadata;


dir	Dict[str, str]	

content direction;


siteName	Dict[str, str]	

name of the site.


lang	Dict[str, str]	

content language

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/readability_web/base.py
RssNewsReader #

Bases: BaseReader

RSS news reader.

Reads news content from RSS feeds and parses with NewsArticleReader.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss_news/base.py
load_data #
load_data(urls: List[str] = None, opml: str = None) -> List[Document]


Load data from either RSS feeds or OPML.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of RSS URLs to load.

	None
opml	str	

URL to OPML file or string or byte OPML content.

	None

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss_news/base.py
RssReader #

Bases: BasePydanticReader

RSS reader.

Reads content from an RSS feed.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss/base.py
load_data #
load_data(urls: List[str]) -> List[Document]


Load data from RSS feeds.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of RSS URLs to load.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/rss/base.py
ScrapflyReader #

Bases: BasePydanticReader

Turn a url to llm accessible markdown with Scrapfly.io.

Args: api_key: The Scrapfly API key. scrape_config: The Scrapfly ScrapeConfig object. ignore_scrape_failures: Whether to continue on failures. urls: List of urls to scrape. scrape_format: Scrape result format (markdown or text) For further details, visit: https://scrapfly.io/docs/sdk/python

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/scrapfly_web/base.py
load_data #
load_data(urls: List[str], scrape_format: Literal['markdown', 'text'] = 'markdown', scrape_config: Optional[dict] = None) -> List[Document]


Load data from the urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List[str]): List of URLs to scrape.

	required
scrape_config	Optional[dict]	

Optional[dict]: Dictionary of ScrapFly scrape config object.

	None

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Raises:

Type	Description
ValueError	

If URLs aren't provided.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/scrapfly_web/base.py
SimpleWebPageReader #

Bases: BasePydanticReader

Simple web page reader.

Reads pages from the web.

Parameters:

Name	Type	Description	Default
html_to_text	bool	

Whether to convert HTML to text. Requires html2text package.

	False
metadata_fn	Optional[Callable[[str], Dict]]	

A function that takes in a URL and returns a dictionary of metadata. Default is None.

	None
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/simple_web/base.py
load_data #
load_data(urls: List[str]) -> List[Document]


Load data from the input directory.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/simple_web/base.py
SitemapReader #

Bases: BaseReader

Asynchronous sitemap reader for web.

Reads pages from the web based on their sitemap.xml.

Parameters:

Name	Type	Description	Default
sitemap_url	string	

Path to the sitemap.xml. e.g. https://gpt-index.readthedocs.io/sitemap.xml

	required
html_to_text	bool	

Whether to convert HTML to text. Requires html2text package.

	False
limit	int	

Maximum number of concurrent requests.

	10
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/sitemap/base.py
TrafilaturaWebReader #

Bases: BasePydanticReader

Trafilatura web page reader.

Reads pages from the web. Requires the trafilatura package.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/trafilatura_web/base.py
class_name classmethod #
class_name() -> str


Get the name identifier of the class.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/trafilatura_web/base.py
load_data #
load_data(urls: List[str], include_comments=True, output_format='txt', include_tables=True, include_images=False, include_formatting=False, include_links=False, show_progress=False, no_ssl=False, **kwargs) -> List[Document]


Load data from the urls.

Parameters:

Name	Type	Description	Default
urls	List[str]	

List of URLs to scrape.

	required
include_comments	bool	

Include comments in the output. Defaults to True.

	True
output_format	str	

Output format. Defaults to 'txt'.

	'txt'
include_tables	bool	

Include tables in the output. Defaults to True.

	True
include_images	bool	

Include images in the output. Defaults to False.

	False
include_formatting	bool	

Include formatting in the output. Defaults to False.

	False
include_links	bool	

Include links in the output. Defaults to False.

	False
show_progress	bool	

Show progress bar. Defaults to False

	False
no_ssl	bool	

Bypass SSL verification. Defaults to False.

	False
kwargs		

Additional keyword arguments for the trafilatura.extract function.

	{}

Returns:

Type	Description
List[Document]	

List[Document]: List of documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/trafilatura_web/base.py
UnstructuredURLLoader #

Bases: BaseReader

Loader that uses unstructured to load HTML files.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/unstructured_web/base.py
load_data #
load_data() -> List[Document]


Load file.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/unstructured_web/base.py
WholeSiteReader #

Bases: BaseReader

BFS Web Scraper for websites.

This class provides functionality to scrape entire websites using a breadth-first search algorithm. It navigates web pages from a given base URL, following links that match a specified prefix.

Attributes:

Name	Type	Description
prefix	str	

URL prefix to focus the scraping.


max_depth	int	

Maximum depth for BFS algorithm.

Parameters:

Name	Type	Description	Default
prefix	str	

URL prefix for scraping.

	required
max_depth	int	

Maximum depth for BFS. Defaults to 10.

	10
Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/whole_site/base.py
setup_driver #
setup_driver()


Sets up the Selenium WebDriver for Chrome.

Returns:

Name	Type	Description
WebDriver		

An instance of Chrome WebDriver.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/whole_site/base.py
load_data #
load_data(base_url: str) -> List[Document]


Load data from the base URL using BFS algorithm.

Parameters:

Name	Type	Description	Default
base_url	str	

Base URL to start scraping.

	required

Returns:

Type	Description
List[Document]	

List[Document]: List of scraped documents.

Source code in llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/whole_site/base.py
 Back to top
Previous
Weaviate
Next
Whatsapp
