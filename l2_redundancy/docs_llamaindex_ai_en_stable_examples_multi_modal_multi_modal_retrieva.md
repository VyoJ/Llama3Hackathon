Title: Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles

URL Source: https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/

Markdown Content:
Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles - LlamaIndex


In this notebook, we show how to build a Multi-Modal retrieval system using LlamaIndex.

Wikipedia Text embedding index: Generate GPT text embeddings from OpenAI for texts

Wikipedia Images embedding index: [CLIP](https://github.com/openai/CLIP) embeddings from OpenAI for images

Query encoder:

*   Encoder query text for text index using GPT embedding
*   Encoder query text for image index using CLIP embedding

Framework: [LlamaIndex](https://github.com/run-llama/llama_index)

Steps:

1.  Download texts and images raw files for Wikipedia articles
2.  Build text index for vector store using GPT embeddings
3.  Build image index for vector store using CLIP embeddings
4.  Retrieve relevant text and image simultaneously using different query encoding embeddings and vector stores

InÂ \[Â \]:

Copied!

%pip install llama\-index\-vector\-stores\-qdrant

%pip install llama-index-vector-stores-qdrant

InÂ \[Â \]:

Copied!

%pip install llama\_index ftfy regex tqdm
%pip install git+https://github.com/openai/CLIP.git
%pip install torch torchvision
%pip install matplotlib scikit\-image
%pip install \-U qdrant\_client

%pip install llama\_index ftfy regex tqdm %pip install git+https://github.com/openai/CLIP.git %pip install torch torchvision %pip install matplotlib scikit-image %pip install -U qdrant\_client

Load and Download Multi-Modal datasets including texts and images from Wikipedia[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#load-and-download-multi-modal-datasets-including-texts-and-images-from-wikipedia)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Parse wikipedia articles and save into local folder

InÂ \[Â \]:

Copied!

from pathlib import Path
import requests

wiki\_titles \= \[
    "batman",
    "Vincent van Gogh",
    "San Francisco",
    "iPhone",
    "Tesla Model S",
    "BTS",
\]

data\_path \= Path("data\_wiki")

for title in wiki\_titles:
    response \= requests.get(
        "https://en.wikipedia.org/w/api.php",
        params\={
            "action": "query",
            "format": "json",
            "titles": title,
            "prop": "extracts",
            "explaintext": True,
        },
    ).json()
    page \= next(iter(response\["query"\]\["pages"\].values()))
    wiki\_text \= page\["extract"\]

    if not data\_path.exists():
        Path.mkdir(data\_path)

    with open(data\_path / f"{title}.txt", "w") as fp:
        fp.write(wiki\_text)

from pathlib import Path import requests wiki\_titles = \[ "batman", "Vincent van Gogh", "San Francisco", "iPhone", "Tesla Model S", "BTS", \] data\_path = Path("data\_wiki") for title in wiki\_titles: response = requests.get( "https://en.wikipedia.org/w/api.php", params={ "action": "query", "format": "json", "titles": title, "prop": "extracts", "explaintext": True, }, ).json() page = next(iter(response\["query"\]\["pages"\].values())) wiki\_text = page\["extract"\] if not data\_path.exists(): Path.mkdir(data\_path) with open(data\_path / f"{title}.txt", "w") as fp: fp.write(wiki\_text)

Parse Wikipedia Images and texts. Load into local folder[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#parse-wikipedia-images-and-texts-load-into-local-folder)
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

InÂ \[Â \]:

Copied!

import wikipedia
import urllib.request

image\_path \= Path("data\_wiki")
image\_uuid \= 0
\# image\_metadata\_dict stores images metadata including image uuid, filename and path
image\_metadata\_dict \= {}
MAX\_IMAGES\_PER\_WIKI \= 30

wiki\_titles \= \[
    "San Francisco",
    "Batman",
    "Vincent van Gogh",
    "iPhone",
    "Tesla Model S",
    "BTS band",
\]

\# create folder for images only
if not image\_path.exists():
    Path.mkdir(image\_path)

\# Download images for wiki pages
\# Assing UUID for each image
for title in wiki\_titles:
    images\_per\_wiki \= 0
    print(title)
    try:
        page\_py \= wikipedia.page(title)
        list\_img\_urls \= page\_py.images
        for url in list\_img\_urls:
            if url.endswith(".jpg") or url.endswith(".png"):
                image\_uuid += 1
                image\_file\_name \= title + "\_" + url.split("/")\[\-1\]

                \# img\_path could be s3 path pointing to the raw image file in the future
                image\_metadata\_dict\[image\_uuid\] \= {
                    "filename": image\_file\_name,
                    "img\_path": "./" + str(image\_path / f"{image\_uuid}.jpg"),
                }
                urllib.request.urlretrieve(
                    url, image\_path / f"{image\_uuid}.jpg"
                )
                images\_per\_wiki += 1
                \# Limit the number of images downloaded per wiki page to 15
                if images\_per\_wiki \> MAX\_IMAGES\_PER\_WIKI:
                    break
    except:
        print(str(Exception("No images found for Wikipedia page: ")) + title)
        continue

import wikipedia import urllib.request image\_path = Path("data\_wiki") image\_uuid = 0 # image\_metadata\_dict stores images metadata including image uuid, filename and path image\_metadata\_dict = {} MAX\_IMAGES\_PER\_WIKI = 30 wiki\_titles = \[ "San Francisco", "Batman", "Vincent van Gogh", "iPhone", "Tesla Model S", "BTS band", \] # create folder for images only if not image\_path.exists(): Path.mkdir(image\_path) # Download images for wiki pages # Assing UUID for each image for title in wiki\_titles: images\_per\_wiki = 0 print(title) try: page\_py = wikipedia.page(title) list\_img\_urls = page\_py.images for url in list\_img\_urls: if url.endswith(".jpg") or url.endswith(".png"): image\_uuid += 1 image\_file\_name = title + "\_" + url.split("/")\[-1\] # img\_path could be s3 path pointing to the raw image file in the future image\_metadata\_dict\[image\_uuid\] = { "filename": image\_file\_name, "img\_path": "./" + str(image\_path / f"{image\_uuid}.jpg"), } urllib.request.urlretrieve( url, image\_path / f"{image\_uuid}.jpg" ) images\_per\_wiki += 1 # Limit the number of images downloaded per wiki page to 15 if images\_per\_wiki > MAX\_IMAGES\_PER\_WIKI: break except: print(str(Exception("No images found for Wikipedia page: ")) + title) continue

InÂ \[Â \]:

Copied!

import os

os.environ\["OPENAI\_API\_KEY"\] \= "YOUR\_API\_KEY"

import os os.environ\["OPENAI\_API\_KEY"\] = "YOUR\_API\_KEY"

Build Multi Modal Vector Store using Text and Image embeddings under different collections[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#build-multi-modal-vector-store-using-text-and-image-embeddings-under-different-collections)
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

InÂ \[Â \]:

Copied!

import qdrant\_client
from llama\_index.core import SimpleDirectoryReader
from llama\_index.vector\_stores.qdrant import QdrantVectorStore
from llama\_index.core import VectorStoreIndex, StorageContext
from llama\_index.core.indices import MultiModalVectorStoreIndex

\# Create a local Qdrant vector store
client \= qdrant\_client.QdrantClient(path\="qdrant\_db")

text\_store \= QdrantVectorStore(
    client\=client, collection\_name\="text\_collection"
)
image\_store \= QdrantVectorStore(
    client\=client, collection\_name\="image\_collection"
)
storage\_context \= StorageContext.from\_defaults(
    vector\_store\=text\_store, image\_store\=image\_store
)

\# Create the MultiModal index
documents \= SimpleDirectoryReader("./data\_wiki/").load\_data()
index \= MultiModalVectorStoreIndex.from\_documents(
    documents,
    storage\_context\=storage\_context,
)

import qdrant\_client from llama\_index.core import SimpleDirectoryReader from llama\_index.vector\_stores.qdrant import QdrantVectorStore from llama\_index.core import VectorStoreIndex, StorageContext from llama\_index.core.indices import MultiModalVectorStoreIndex # Create a local Qdrant vector store client = qdrant\_client.QdrantClient(path="qdrant\_db") text\_store = QdrantVectorStore( client=client, collection\_name="text\_collection" ) image\_store = QdrantVectorStore( client=client, collection\_name="image\_collection" ) storage\_context = StorageContext.from\_defaults( vector\_store=text\_store, image\_store=image\_store ) # Create the MultiModal index documents = SimpleDirectoryReader("./data\_wiki/").load\_data() index = MultiModalVectorStoreIndex.from\_documents( documents, storage\_context=storage\_context, )

/Users/haotianzhang/llama\_index/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm

### Plot downloaded Images from Wikipedia[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#plot-downloaded-images-from-wikipedia)

InÂ \[Â \]:

Copied!

from PIL import Image
import matplotlib.pyplot as plt
import os

def plot\_images(image\_metadata\_dict):
    original\_images\_urls \= \[\]
    images\_shown \= 0
    for image\_id in image\_metadata\_dict:
        img\_path \= image\_metadata\_dict\[image\_id\]\["img\_path"\]
        if os.path.isfile(img\_path):
            filename \= image\_metadata\_dict\[image\_id\]\["filename"\]
            image \= Image.open(img\_path).convert("RGB")

            plt.subplot(8, 8, len(original\_images\_urls) + 1)
            plt.imshow(image)
            plt.xticks(\[\])
            plt.yticks(\[\])

            original\_images\_urls.append(filename)
            images\_shown += 1
            if images\_shown \>= 64:
                break

    plt.tight\_layout()

plot\_images(image\_metadata\_dict)

from PIL import Image import matplotlib.pyplot as plt import os def plot\_images(image\_metadata\_dict): original\_images\_urls = \[\] images\_shown = 0 for image\_id in image\_metadata\_dict: img\_path = image\_metadata\_dict\[image\_id\]\["img\_path"\] if os.path.isfile(img\_path): filename = image\_metadata\_dict\[image\_id\]\["filename"\] image = Image.open(img\_path).convert("RGB") plt.subplot(8, 8, len(original\_images\_urls) + 1) plt.imshow(image) plt.xticks(\[\]) plt.yticks(\[\]) original\_images\_urls.append(filename) images\_shown += 1 if images\_shown >= 64: break plt.tight\_layout() plot\_images(image\_metadata\_dict)

![Image 4: No description has been provided for this image](blob:https://docs.llamaindex.ai/dd4f0fa2f461d6911bfb4e3089050e81)

### Build a separate CLIP image embedding index under a differnt collection `wikipedia_img`[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#build-a-separate-clip-image-embedding-index-under-a-differnt-collection-wikipedia_img)

InÂ \[Â \]:

Copied!

def plot\_images(image\_paths):
    images\_shown \= 0
    plt.figure(figsize\=(16, 9))
    for img\_path in image\_paths:
        if os.path.isfile(img\_path):
            image \= Image.open(img\_path)

            plt.subplot(2, 3, images\_shown + 1)
            plt.imshow(image)
            plt.xticks(\[\])
            plt.yticks(\[\])

            images\_shown += 1
            if images\_shown \>= 9:
                break

def plot\_images(image\_paths): images\_shown = 0 plt.figure(figsize=(16, 9)) for img\_path in image\_paths: if os.path.isfile(img\_path): image = Image.open(img\_path) plt.subplot(2, 3, images\_shown + 1) plt.imshow(image) plt.xticks(\[\]) plt.yticks(\[\]) images\_shown += 1 if images\_shown >= 9: break

Get Multi-Modal retrieval results for some example queries[Â¶](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_retrieval/#get-multi-modal-retrieval-results-for-some-example-queries)
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

InÂ \[Â \]:

Copied!

test\_query \= "who are BTS team members"
\# generate  retrieval results
retriever \= index.as\_retriever(similarity\_top\_k\=3, image\_similarity\_top\_k\=5)
retrieval\_results \= retriever.retrieve(test\_query)

test\_query = "who are BTS team members" # generate retrieval results retriever = index.as\_retriever(similarity\_top\_k=3, image\_similarity\_top\_k=5) retrieval\_results = retriever.retrieve(test\_query)

InÂ \[Â \]:

Copied!

from llama\_index.core.response.notebook\_utils import display\_source\_node
from llama\_index.core.schema import ImageNode

retrieved\_image \= \[\]
for res\_node in retrieval\_results:
    if isinstance(res\_node.node, ImageNode):
        retrieved\_image.append(res\_node.node.metadata\["file\_path"\])
    else:
        display\_source\_node(res\_node, source\_length\=200)

plot\_images(retrieved\_image)

from llama\_index.core.response.notebook\_utils import display\_source\_node from llama\_index.core.schema import ImageNode retrieved\_image = \[\] for res\_node in retrieval\_results: if isinstance(res\_node.node, ImageNode): retrieved\_image.append(res\_node.node.metadata\["file\_path"\]) else: display\_source\_node(res\_node, source\_length=200) plot\_images(retrieved\_image)

**Node ID:** e30e1817-4e31-4047-be5d-37502560920c  
**Similarity:** 0.808149809808292  
**Text:** BTS (Korean: ë°©íƒ„ì†Œë…„ë‹¨; RR: Bangtan Sonyeondan; lit. Bulletproof Boy Scouts), also known as the Bangtan Boys, is a South Korean boy band formed in 2010. The band consists of Jin, Suga, J-Hope, RM, Jimi...

**Node ID:** 024f3296-37c8-46d5-a184-2f78c621a99f  
**Similarity:** 0.7987048642063129  
**Text:**  According to Kyung Hyun Kim, BTS's rise was facilitated by a great increase in music video programming and consumption on YouTube and the coming of an idol empire, including merchand...

**Node ID:** c564ccf4-a94f-408f-8b21-224538dc2e94  
**Similarity:** 0.7838098925118134  
**Text:** 

\ BTS was formed in 2010, after Big Hit Entertainment CEO Bang Si-hyuk wanted to form a hip hop group around RM (Kim Nam-joon), an undergr...

![Image 5: No description has been provided for this image](blob:https://docs.llamaindex.ai/fff97cc7abb0cc4ded284bc4bacec630)

InÂ \[Â \]:

Copied!

test\_query \= "what are Vincent van Gogh's famous paintings"
\# generate  retrieval results
retriever \= index.as\_retriever(similarity\_top\_k\=3, image\_similarity\_top\_k\=5)
retrieval\_results \= retriever.retrieve(test\_query)

retrieved\_image \= \[\]
for res\_node in retrieval\_results:
    if isinstance(res\_node.node, ImageNode):
        retrieved\_image.append(res\_node.node.metadata\["file\_path"\])
    else:
        display\_source\_node(res\_node, source\_length\=200)

plot\_images(retrieved\_image)

test\_query = "what are Vincent van Gogh's famous paintings" # generate retrieval results retriever = index.as\_retriever(similarity\_top\_k=3, image\_similarity\_top\_k=5) retrieval\_results = retriever.retrieve(test\_query) retrieved\_image = \[\] for res\_node in retrieval\_results: if isinstance(res\_node.node, ImageNode): retrieved\_image.append(res\_node.node.metadata\["file\_path"\]) else: display\_source\_node(res\_node, source\_length=200) plot\_images(retrieved\_image)

**Node ID:** e002927c-0bf5-482b-a0a1-0ee2f3cd48f9  
**Similarity:** 0.8675476190545354  
**Text:** Vincent Willem van Gogh (Dutch: \[ËˆvÉªnsÉ›nt ËˆÊ‹ÉªlÉ™É± vÉ‘Å‹ ËˆÉ£É”x\] ; 30 March 1853 â€“ 29 July 1890) was a Dutch Post-Impressionist painter who is among the most famous and influential figures in the history...

**Node ID:** 69ef1c64-a5b4-468c-a58c-7d36151961a7  
**Similarity:** 0.8661792475490765  
**Text:** 

Van Gogh painted several landscapes with flowers, including roses, lilacs, irises, and sunflowers. Some reflect his interests in the language of colour, and also in Japanese ukiy...

**Node ID:** f971a611-a8b9-48b4-a81b-d3856438aab8  
**Similarity:** 0.8616832203971132  
**Text:** 

Van Gogh said portaiture was his greatest interest. "What I'm most passionate about, much much more than all the rest in my profession", he wrote in 1890, "is the portrait, the...

![Image 6: No description has been provided for this image](blob:https://docs.llamaindex.ai/88d0da9fbc770e95d5f0e35bafe4d6b7)

InÂ \[Â \]:

Copied!

test\_query \= "what is the popular tourist attraction in San Francisco"
\# generate  retrieval results
retriever \= index.as\_retriever(similarity\_top\_k\=3, image\_similarity\_top\_k\=5)
retrieval\_results \= retriever.retrieve(test\_query)

retrieved\_image \= \[\]
for res\_node in retrieval\_results:
    if isinstance(res\_node.node, ImageNode):
        retrieved\_image.append(res\_node.node.metadata\["file\_path"\])
    else:
        display\_source\_node(res\_node, source\_length\=200)

plot\_images(retrieved\_image)

test\_query = "what is the popular tourist attraction in San Francisco" # generate retrieval results retriever = index.as\_retriever(similarity\_top\_k=3, image\_similarity\_top\_k=5) retrieval\_results = retriever.retrieve(test\_query) retrieved\_image = \[\] for res\_node in retrieval\_results: if isinstance(res\_node.node, ImageNode): retrieved\_image.append(res\_node.node.metadata\["file\_path"\]) else: display\_source\_node(res\_node, source\_length=200) plot\_images(retrieved\_image)

**Node ID:** 8c14be3e-345a-4764-9b64-dacff771bc04  
**Similarity:** 0.8689195893277072  
**Text:** 

Tourism is one of San Francisco's most important private-sector industries, accounting for more than one out of seven jobs in the city. The city's frequent portraya...

**Node ID:** 22aa7d86-017f-433d-98dc-4007d9f67c17  
**Similarity:** 0.8452524742723133  
**Text:** 

San Francisco has long had an LGBT-friendly history. It was home to the first lesbian-rights organization in the United States, Daughters of Bilitis; the first openly gay person to ru...

**Node ID:** 3846a17a-79d8-415e-9bcf-76c818b27203  
**Similarity:** 0.8329496262980858  
**Text:** 

Several of San Francisco's parks and nearly all of its beaches form part of the regional Golden Gate National Recreation Area, one of the most visited units of the Natio...

![Image 7: No description has been provided for this image](blob:https://docs.llamaindex.ai/7c86a97d029fe9fa260fc3f033718518)

InÂ \[Â \]:

Copied!

test\_query \= "which company makes Tesla"
\# generate  retrieval results
retriever \= index.as\_retriever(similarity\_top\_k\=3, image\_similarity\_top\_k\=5)
retrieval\_results \= retriever.retrieve(test\_query)

retrieved\_image \= \[\]
for res\_node in retrieval\_results:
    if isinstance(res\_node.node, ImageNode):
        retrieved\_image.append(res\_node.node.metadata\["file\_path"\])
    else:
        display\_source\_node(res\_node, source\_length\=200)

plot\_images(retrieved\_image)

test\_query = "which company makes Tesla" # generate retrieval results retriever = index.as\_retriever(similarity\_top\_k=3, image\_similarity\_top\_k=5) retrieval\_results = retriever.retrieve(test\_query) retrieved\_image = \[\] for res\_node in retrieval\_results: if isinstance(res\_node.node, ImageNode): retrieved\_image.append(res\_node.node.metadata\["file\_path"\]) else: display\_source\_node(res\_node, source\_length=200) plot\_images(retrieved\_image)

**Node ID:** 214c61be-dad6-403c-b301-bc2320b87e7a  
**Similarity:** 0.7808396168295813  
**Text:** The Tesla Model S is a battery electric full-size luxury sedan with a liftback body style built by Tesla, Inc. since 2012. The Model S features a battery-powered dual-motor, all-wheel drive layout,...

**Node ID:** 15b737b4-90e3-443a-87aa-13a7d7e80b87  
**Similarity:** 0.7807424063856144  
**Text:**  The P100D outputs 439 kW (589 hp) and 1,248 Nâ‹…m (920 lbfâ‹…ft) torque on a dynamometer.As of March 2017, P100D was the world's quickest production vehicle with a NHRA rolling start to 6...

**Node ID:** e134452b-3031-47b0-a20c-df4fe32f1bcf  
**Similarity:** 0.7754107325086438  
**Text:**  As of December 2021, Tesla had had seven Model S recalls: On June 14, 2013, Tesla recalled Model S vehicles manufactured between May 10, 2013, and June 8, 2013, due to improper meth...

![Image 8: No description has been provided for this image](blob:https://docs.llamaindex.ai/1a4cef5065382e21183b1890adc708ee)

InÂ \[Â \]:

Copied!

test\_query \= "what is the main character in Batman"
\# generate  retrieval results
retriever \= index.as\_retriever(similarity\_top\_k\=3, image\_similarity\_top\_k\=5)
retrieval\_results \= retriever.retrieve(test\_query)

retrieved\_image \= \[\]
for res\_node in retrieval\_results:
    if isinstance(res\_node.node, ImageNode):
        retrieved\_image.append(res\_node.node.metadata\["file\_path"\])
    else:
        display\_source\_node(res\_node, source\_length\=200)

plot\_images(retrieved\_image)

test\_query = "what is the main character in Batman" # generate retrieval results retriever = index.as\_retriever(similarity\_top\_k=3, image\_similarity\_top\_k=5) retrieval\_results = retriever.retrieve(test\_query) retrieved\_image = \[\] for res\_node in retrieval\_results: if isinstance(res\_node.node, ImageNode): retrieved\_image.append(res\_node.node.metadata\["file\_path"\]) else: display\_source\_node(res\_node, source\_length=200) plot\_images(retrieved\_image)

**Node ID:** ff85b136-08c8-465d-96f5-a554c65067d8  
**Similarity:** 0.8461934674061043  
**Text:**  Batman's primary character traits can be summarized as "wealth; physical prowess; deductive abilities and obsession". The details and tone of Batman comic books have varied ov...

**Node ID:** 55f5b842-6fd0-4e45-aef2-27f74f670e82  
**Similarity:** 0.8229623965891602  
**Text:** Batman is a superhero appearing in American comic books published by DC Comics. The character was created by artist Bob Kane and writer Bill Finger, and debuted in the 27th issue of the comic book ...

**Node ID:** cb4755db-088e-46af-92b2-3a4a3649d9fe  
**Similarity:** 0.8218281955244808  
**Text:** 

Batman faces a variety of foes ranging from common criminals to outlandish supervillains. Many of them mirror aspects of the Batman's character and development, often having tragic...

![Image 9: No description has been provided for this image](blob:https://docs.llamaindex.ai/217ac1d0a9f9cd29611c92511777bf98)

Back to top

[Previous Multi-Modal RAG using Nomic Embed and Anthropic.](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_rag_nomic/)[Next Multimodal RAG for processing videos using OpenAI GPT4V and LanceDB vectorstore](https://docs.llamaindex.ai/en/stable/examples/multi_modal/multi_modal_video_RAG/)

Hi, how can I help you?

ðŸ¦™
